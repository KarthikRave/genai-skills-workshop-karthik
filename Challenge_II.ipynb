{
  "cells": [
    {
      "cell_type": "code",
      "id": "cmPVSyE1QyUkU83CTL8d9gSp",
      "metadata": {
        "tags": [],
        "id": "cmPVSyE1QyUkU83CTL8d9gSp"
      },
      "source": [
        "# Install required libraries (run once per Colab/Jupyter session)\n",
        "!pip install --upgrade google-cloud-bigquery --quiet\n",
        "!pip install --upgrade google-generativeai --quiet"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n"
      ],
      "metadata": {
        "id": "_MbcaXLSJeB4"
      },
      "id": "_MbcaXLSJeB4",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------- #\n",
        "#     MODEL CONFIGURATION     #\n",
        "# --------------------------- #\n",
        "\n",
        "# Define the Gemini model version to use\n",
        "MODEL_NAME = \"gemini-2.5-pro-preview-06-05\"\n",
        "\n",
        "# Optional: Add safety settings for content moderation (can enhance later)\n",
        "SAFETY_SETTINGS = {\n",
        "    'HARM_CATEGORY_HARASSMENT': 'BLOCK_MEDIUM_AND_ABOVE',\n",
        "    'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_MEDIUM_AND_ABOVE',\n",
        "    'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_MEDIUM_AND_ABOVE',\n",
        "    'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_MEDIUM_AND_ABOVE',\n",
        "}\n",
        "\n",
        "# System instructions (can be injected into chat history if chat-based)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful assistant. Answer the user's question using only the content provided.\n",
        "If the answer is not present in the content, say \"Sorry, I don't have that information.\"\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "tQounHjJJmCa"
      },
      "id": "tQounHjJJmCa",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_gemini():\n",
        "    \"\"\"\n",
        "    Configures the Gemini API using environment variable or manual input.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "        if not api_key:\n",
        "            api_key = input(\"ğŸ” Enter your Gemini API key: \").strip()\n",
        "\n",
        "        if not api_key:\n",
        "            raise ValueError(\"Gemini API key is required.\")\n",
        "\n",
        "        genai.configure(api_key=api_key)\n",
        "        print(\"âœ… Gemini API configured successfully.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Gemini configuration failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "    \"\"\"\n",
        "    Initializes Gemini GenerativeModel with optional safety settings.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=MODEL_NAME,\n",
        "            safety_settings=SAFETY_SETTINGS\n",
        "        )\n",
        "        print(f\"âœ… Gemini model '{MODEL_NAME}' initialized.\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to initialize model: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "FhSTqCS4JoA_"
      },
      "id": "FhSTqCS4JoA_",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_bigquery_client(project_id: str):\n",
        "    \"\"\"\n",
        "    Initializes the BigQuery client for the given GCP project.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = bigquery.Client(project=project_id)\n",
        "        print(f\"âœ… BigQuery client initialized for project: {project_id}\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ BigQuery initialization failed: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "5qVmh76FJq63"
      },
      "id": "5qVmh76FJq63",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context_from_bigquery(user_input, bq_client):\n",
        "    \"\"\"\n",
        "    Executes a BigQuery vector search to find the most relevant content.\n",
        "\n",
        "    Returns:\n",
        "        str: Top-matching document content or empty string.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query = f\"\"\"\n",
        "        SELECT\n",
        "            query.query,\n",
        "            base.content\n",
        "        FROM\n",
        "            VECTOR_SEARCH(\n",
        "                TABLE `CustomerReview.customer_reviews_embedded`,\n",
        "                'ml_generate_embedding_result',\n",
        "                (\n",
        "                    SELECT\n",
        "                        ml_generate_embedding_result,\n",
        "                        content AS query\n",
        "                    FROM\n",
        "                        ML.GENERATE_EMBEDDING(\n",
        "                            MODEL `CustomerReview.Embeddings`,\n",
        "                            (SELECT '{user_input}' AS content)\n",
        "                        )\n",
        "                ),\n",
        "                top_k => 1,\n",
        "                options => '{{\"fraction_lists_to_search\": 0.01}}'\n",
        "            );\n",
        "        \"\"\"\n",
        "        query_job = bq_client.query(query)\n",
        "        results = query_job.result()\n",
        "\n",
        "        for row in results:\n",
        "            return row.content  # Only top 1 needed\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâš ï¸ BigQuery Error: {e}\\n\")\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "id": "5AFLbaEqJuWF"
      },
      "id": "5AFLbaEqJuWF",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rag_response(user_input, context, model):\n",
        "    \"\"\"\n",
        "    Sends the user question along with BigQuery context to Gemini.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Construct the prompt using system instructions + retrieved context\n",
        "        prompt = f\"\"\"\n",
        "{SYSTEM_PROMPT}\n",
        "\n",
        "Content:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{user_input}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Gemini error: {e}\")\n",
        "        return \"Sorry, I couldn't process your request. Please try again.\"\n"
      ],
      "metadata": {
        "id": "OOrBV_YPJxho"
      },
      "id": "OOrBV_YPJxho",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------- #\n",
        "#        MAIN EXECUTION       #\n",
        "# --------------------------- #\n",
        "\n",
        "# Replace with your own GCP project ID\n",
        "PROJECT_ID = \"qwiklabs-gcp-02-79b6e8a77529\"\n",
        "\n",
        "# Step-by-step startup (Jupyter/Colab friendly)\n",
        "bq_client = initialize_bigquery_client(PROJECT_ID)\n",
        "if configure_gemini():\n",
        "    model = initialize_model()\n",
        "\n",
        "    if model and bq_client:\n",
        "        print(\"\\n--- ğŸ¤– BigQuery-RAG Chatbot is ready! ---\")\n",
        "        print(\"ğŸ’¬ Ask any question based on indexed content.\")\n",
        "        print(\"ğŸ›‘ Type 'quit' or 'exit' to end the session.\\n\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                user_input = input(\"ğŸ‘¤ You: \").strip()\n",
        "\n",
        "                if user_input.lower() in {\"quit\", \"exit\"}:\n",
        "                    print(\"\\nğŸ‘‹ Chatbot: Goodbye! Stay curious. ğŸš€\")\n",
        "                    break\n",
        "\n",
        "                if not user_input:\n",
        "                    print(\"âš ï¸ Please type a valid question.\")\n",
        "                    continue\n",
        "\n",
        "                # Step 1: Retrieve top matching content\n",
        "                context = retrieve_context_from_bigquery(user_input, bq_client)\n",
        "\n",
        "                if not context:\n",
        "                    print(\"ğŸ¤– Chatbot: Sorry, I couldn't find relevant content.\\n\")\n",
        "                    continue\n",
        "\n",
        "                display(Markdown(f\"ğŸ“š **Context Retrieved:**\\n```\\n{context}\\n```\"))\n",
        "\n",
        "                # Step 2: Generate answer from Gemini using the context\n",
        "                response = get_rag_response(user_input, context, model)\n",
        "                display(Markdown(f\"**ğŸ¤– Gemini Answer:** {response}\"))\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\nğŸ›‘ Session interrupted.\")\n",
        "                break\n",
        "    else:\n",
        "        print(\"âŒ Setup incomplete. Check model or BigQuery client.\")\n",
        "else:\n",
        "    print(\"âŒ Gemini API setup failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "n7NR8fI-Jz2x",
        "outputId": "2bcdf430-0192-497a-b3a6-a873412aa507"
      },
      "id": "n7NR8fI-Jz2x",
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… BigQuery client initialized for project: qwiklabs-gcp-02-79b6e8a77529\n",
            "ğŸ” Enter your Gemini API key: AIzaSyCDAGZ67YzBIrfJVcks_4xWZKYoQhCwq_c  \n",
            "âœ… Gemini API configured successfully.\n",
            "âœ… Gemini model 'gemini-2.5-pro-preview-06-05' initialized.\n",
            "\n",
            "--- ğŸ¤– BigQuery-RAG Chatbot is ready! ---\n",
            "ğŸ’¬ Ask any question based on indexed content.\n",
            "ğŸ›‘ Type 'quit' or 'exit' to end the session.\n",
            "\n",
            "ğŸ‘¤ You: When was Aurora Bay founded?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ğŸ“š **Context Retrieved:**\n```\nQuestion: When was Aurora Bay founded? Answer: Aurora Bay was founded in 1901 by a group of fur traders who recognized the regionâ€™s strategic coastal location.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ğŸ¤– Gemini Answer:** 1901"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‘¤ You: When are the town council meetings held?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ğŸ“š **Context Retrieved:**\n```\nQuestion: When are the town council meetings held? Answer: Town council meetings are held every second Tuesday of the month at 6 PM in the Town Hall conference room. Meetings are open to the public.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ğŸ¤– Gemini Answer:** Town council meetings are held every second Tuesday of the month at 6 PM in the Town Hall conference room."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‘¤ You: When is the annual Salmon Derby?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ğŸ“š **Context Retrieved:**\n```\nQuestion: When is the annual Salmon Derby? Answer: The annual Salmon Derby takes place in early July, usually spanning three days. It attracts anglers from across the region.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ğŸ¤– Gemini Answer:** The annual Salmon Derby takes place in early July, usually spanning three days."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ‘¤ You: exit\n",
            "\n",
            "ğŸ‘‹ Chatbot: Goodbye! Stay curious. ğŸš€\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-02-ee82d0e93d69 (Jun 16, 2025, 3:20:27â€¯PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}