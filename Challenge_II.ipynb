{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages (run once)\n",
        "!pip install --upgrade google-cloud-bigquery --quiet\n",
        "!pip install --upgrade google-generativeai --quiet"
      ],
      "metadata": {
        "id": "p3AlcwnQFkqI"
      },
      "id": "p3AlcwnQFkqI",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n"
      ],
      "metadata": {
        "id": "kT7N0RcbFpuF"
      },
      "id": "kT7N0RcbFpuF",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with your actual project ID (from Qwiklabs or GCP Console)\n",
        "project_id = \"qwiklabs-gcp-02-79b6e8a77529\"\n",
        "\n",
        "# Initialize BigQuery client\n",
        "try:\n",
        "    bq_client = bigquery.Client(project=project_id)\n",
        "    print(f\"âœ… BigQuery client initialized for project: {project_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to initialize BigQuery client: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEO3_Jp1FsPP",
        "outputId": "d586bfe5-43da-461c-cf3c-ea5f0c6fd55b"
      },
      "id": "OEO3_Jp1FsPP",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… BigQuery client initialized for project: qwiklabs-gcp-02-79b6e8a77529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Gemini API Key from environment or prompt\n",
        "try:\n",
        "    api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    if not api_key:\n",
        "        api_key = input(\"ğŸ” Enter your Gemini API key: \").strip()\n",
        "\n",
        "    if not api_key:\n",
        "        raise ValueError(\"Gemini API key is required.\")\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"âœ… Gemini API configured successfully.\")\n",
        "\n",
        "    # Initialize the model with default settings\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-pro-preview-06-05\")\n",
        "    print(\"âœ… Gemini model initialized.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Gemini setup failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cWMtvW1Fxvn",
        "outputId": "756c5533-841a-450e-d883-0758542ea6ec"
      },
      "id": "5cWMtvW1Fxvn",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Enter your Gemini API key: AIzaSyCDAGZ67YzBIrfJVcks_4xWZKYoQhCwq_c\n",
            "âœ… Gemini API configured successfully.\n",
            "âœ… Gemini model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- ğŸ¤– BigQuery-RAG Chatbot is running! ---\")\n",
        "print(\"ğŸ’¬ Ask questions based on indexed content.\")\n",
        "print(\"ğŸ›‘ Type 'quit' or 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        # User input\n",
        "        user_input = input(\"ğŸ‘¤ You: \").strip()\n",
        "\n",
        "        # Exit condition\n",
        "        if user_input.lower() in {\"quit\", \"exit\"}:\n",
        "            print(\"\\nğŸ‘‹ Chatbot: Goodbye! Stay curious. ğŸš€\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            print(\"âš ï¸ Please enter a valid question.\")\n",
        "            continue\n",
        "\n",
        "        # ------------------------------\n",
        "        # ğŸ” Step 3: Run BigQuery Vector Search\n",
        "        # ------------------------------\n",
        "        query = f\"\"\"\n",
        "        SELECT\n",
        "            query.query,\n",
        "            base.content\n",
        "        FROM\n",
        "            VECTOR_SEARCH(\n",
        "                TABLE `CustomerReview.customer_reviews_embedded`,\n",
        "                'ml_generate_embedding_result',\n",
        "                (\n",
        "                    SELECT\n",
        "                        ml_generate_embedding_result,\n",
        "                        content AS query\n",
        "                    FROM\n",
        "                        ML.GENERATE_EMBEDDING(\n",
        "                            MODEL `CustomerReview.Embeddings`,\n",
        "                            (SELECT '{user_input}' AS content)\n",
        "                        )\n",
        "                ),\n",
        "                top_k => 1,\n",
        "                options => '{{\"fraction_lists_to_search\": 0.01}}'\n",
        "            );\n",
        "        \"\"\"\n",
        "\n",
        "        query_job = bq_client.query(query)\n",
        "        results = query_job.result()\n",
        "\n",
        "        context = \"\"\n",
        "        for row in results:\n",
        "            context = row.content\n",
        "            break  # Only need top result\n",
        "\n",
        "        # If no context found\n",
        "        if not context:\n",
        "            print(\"\\nğŸ¤– Chatbot: Sorry, I couldn't find relevant content.\\n\")\n",
        "            continue\n",
        "\n",
        "        display(Markdown(f\"ğŸ“š **Retrieved Context:**\\n```\\n{context}\\n```\"))\n",
        "\n",
        "        # ------------------------------\n",
        "        # ğŸ¤– Step 4: Generate LLM Answer with Context\n",
        "        # ------------------------------\n",
        "        prompt = f\"\"\"\n",
        "You are a helpful assistant. Answer the user's question using only the content provided below.\n",
        "If the answer is not present in the content, say \"Sorry, I don't have that information.\"\n",
        "\n",
        "Content:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{user_input}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        # Call Gemini to generate answer\n",
        "        response = model.generate_content(prompt)\n",
        "        display(Markdown(f\"**ğŸ¤– Gemini Answer:** {response.text.strip()}\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâš ï¸ Unexpected error: {e}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "1a4GGDCTF4JE",
        "outputId": "1618f223-ddc6-4032-d602-0f82b1dd24b2"
      },
      "id": "1a4GGDCTF4JE",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- ğŸ¤– BigQuery-RAG Chatbot is running! ---\n",
            "ğŸ’¬ Ask questions based on indexed content.\n",
            "ğŸ›‘ Type 'quit' or 'exit' to stop.\n",
            "\n",
            "ğŸ‘¤ You: When was Aurora Bay founded?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ğŸ“š **Retrieved Context:**\n```\nQuestion: When was Aurora Bay founded? Answer: Aurora Bay was founded in 1901 by a group of fur traders who recognized the regionâ€™s strategic coastal location.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ğŸ¤– Gemini Answer:** Aurora Bay was founded in 1901."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‘¤ You: What are the operating hours of the Aurora Bay Public Library?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ğŸ“š **Retrieved Context:**\n```\nQuestion: What are the operating hours of the Aurora Bay Public Library? Answer: The library is open Monday through Friday from 9 AM to 6 PM, and on Saturdays from 10 AM to 4 PM. Itâ€™s closed on Sundays and major holidays.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ğŸ¤– Gemini Answer:** The library is open Monday through Friday from 9 AM to 6 PM, and on Saturdays from 10 AM to 4 PM. Itâ€™s closed on Sundays and major holidays."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ‘¤ You: exit\n",
            "\n",
            "ğŸ‘‹ Chatbot: Goodbye! Stay curious. ğŸš€\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-02-ee82d0e93d69 (Jun 16, 2025, 2:54:06â€¯PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}